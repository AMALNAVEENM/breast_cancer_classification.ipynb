{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "5ea2909f-b7c9-4f20-a83c-6a2fda1a6f07",
      "cell_type": "code",
      "source": "# ----------------------------\n# 1. IMPORT LIBRARIES\n# ----------------------------\nimport pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport warnings\nwarnings.filterwarnings('ignore')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1b667312-2927-4f38-8db0-c2f7a9d4904d",
      "cell_type": "code",
      "source": "# Load dataset\ndata = load_breast_cancer()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.Series(data.target, name='target')\n\n# Check for missing values\nprint(\"Total missing values:\", X.isnull().sum().sum())\n\n# Split into train (80%) and test (20%) â€” stratified to maintain class balance\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Scale features for models that need it\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "14c785e3-dd14-4f4b-bd6d-a212b2803cb8",
      "cell_type": "code",
      "source": "# ----------------------------\n# 2. TRAIN ALL MODELS\n# ----------------------------\n\n# Store models and their corresponding test data\nmodel_results = {}\n\n# 1. Logistic Regression (needs scaled data)\nlr = LogisticRegression(max_iter=1000, random_state=42)\nlr.fit(X_train_scaled, y_train)\nmodel_results['Logistic Regression'] = (lr, X_test_scaled)\n\n# 2. Decision Tree (uses unscaled data)\ndt = DecisionTreeClassifier(random_state=42)\ndt.fit(X_train, y_train)\nmodel_results['Decision Tree'] = (dt, X_test)\n\n# 3. Random Forest (uses unscaled data)\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\nmodel_results['Random Forest'] = (rf, X_test)\n\n# 4. SVM (needs scaled data)\nsvm = SVC(kernel='rbf', random_state=42)\nsvm.fit(X_train_scaled, y_train)\nmodel_results['SVM'] = (svm, X_test_scaled)\n\n# 5. k-NN (needs scaled data)\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train_scaled, y_train)\nmodel_results['k-NN'] = (knn, X_test_scaled)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2fa4fece-9be3-4f66-9632-e148e846d2c3",
      "cell_type": "code",
      "source": "# ----------------------------\n# 3. EVALUATE MODELS\n# ----------------------------\nresults = []\n\nfor name, (model, X_test_used) in model_results.items():\n    y_pred = model.predict(X_test_used)\n    acc = accuracy_score(y_test, y_pred)\n    results.append([name, round(acc, 4)])\n\n# Create and sort results DataFrame\nresults_df = pd.DataFrame(results, columns=['Model', 'Accuracy'])\nresults_df = results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\nresults_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9cb23d7b-cd7c-4831-a355-002cb0a1b52f",
      "cell_type": "code",
      "source": "# Show detailed report for best model\nbest_model_name = results_df.iloc[0]['Model']\nbest_model, X_best = model_results[best_model_name]\ny_pred_best = best_model.predict(X_best)\n\nprint(f\"\\nðŸ† Best Model: {best_model_name}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred_best, target_names=data.target_names))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "739fadba-61da-4697-beac-75c937db2961",
      "cell_type": "code",
      "source": "### Final Comparison\n\n**Typical Output** (your numbers may vary slightly):\n| Model               | Accuracy |\n|---------------------|----------|\n| Random Forest       | 0.9737   |\n| SVM                 | 0.9649   |\n| Logistic Regression | 0.9561   |\n| k-NN                | 0.9474   |\n| Decision Tree       | 0.9035   |\n\n-  **Best Model**: **Random Forest**  \n   Highest accuracy, robust to noise, handles non-linear relationships.  \n-  **Worst Model**: **Decision Tree**  \n   Overfits training data, lower generalization ability.\n\n> **Note**: The dataset is well-separated, so even simple models perform well. Random Forest consistently leads due to ensemble stability.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}